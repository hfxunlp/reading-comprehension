# reading-comprehension

Several models are implemented in these experiments:  
Gated Attention Reader, Attention over Attention Reader and their combination  
A Hierarchical Sequence tagger for reading comprehension  

!<do not load this image>[STRUCTURE]
(<doc/image/seqreader.png>)
